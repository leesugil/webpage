{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $k$-fold cross-validation\n",
    "\n",
    "This is a short note on **$k$-fold cross-validation** in data science.\n",
    "\n",
    "The best way to find out how it's implemented in `sklearn` is to look up <a href=\"https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\">the official user guide</a>.\n",
    "\n",
    "In general, cross-validation is not a training algorithm, it's more of handling the data before applying any learning algorithm onto it.\n",
    "\n",
    "When training a model on labeled data, we split the data into two parts, the training set and the test set, to measure the performance on prediction.\n",
    "\n",
    "This is an important practice, otherwise one can always overfit the data at the cost of losing its ability to predict new samples.\n",
    "\n",
    "However, in practice, we don't always have the abunduncy of labeled data. One wishes to be wise with the given limited size of the data.\n",
    "\n",
    "$k$-fold cross-validation is a classical method to measure how good our model and the choice of hyperparameters are given a data set, especially when the size of the data is not as large as desired.\n",
    "\n",
    "Idea: Suppose we want to train a model and see if we made a good choice of a hyperparameter.\n",
    "- Shffule the samples and split it into $k$ number of groups.\n",
    "- For $i = 1, ..., k$, leave the $i$'th group out as the test group, and train the model on the union of the rest $k-1$ groups.\n",
    "- For each $i$, we have a performance measure like the accuracy of the model. Average them out as the final measure of the accuracy of the model.\n",
    "\n",
    "In summary, cross-validation combines (averages) measures of fitness in prediction to derive a more accurate estimate of model prediction performance (<a href=\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)\">Wikipedia</a>).\n",
    "\n",
    "Then what should the number $k$ be?\n",
    "\n",
    "We don't have the magic number $k(n)$ that works perfectly on each sample size $n$. However, if the sample size is small like those from a traditional medical experiment, to increase validity, one could use $k = n$.\n",
    "- Leave one random sample out as a test set.\n",
    "- Train the model on the rest $n-1$ samples.\n",
    "- Repeat.\n",
    "\n",
    "This method is also called leave-one-out cross-validation (LOOCV).\n",
    "\n",
    "Here's a sample code for the `sklearn` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "print(type(iris))\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to <a href=\"https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\">the official user guide</a>, we leave the test set out and run the $k$-fold validation on the training set, but the sample code shown on the same page shows that the $k$-fold validation was run on the whole set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross-validation\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "model = svm.SVC(kernel = 'linear', C=1)\n",
    "scores = model_selection.cross_val_score(model, x, y, cv = 5)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `model_selection.cross_val_score()` stores the accuracy of the trained model over each loop.\n",
    "\n",
    "There are <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\">other options</a> available as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.98 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(model, x, y, cv = 5, scoring = 'f1_macro')\n",
    "print(\"f1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
